{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multitask_dataset import SingerMultiTaskDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from models import HuBERTMultiHead\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_folder = '/media/maximos/9C33-6BBD/data/melos_singers/Rebetika_vowels/train/'\n",
    "csv_path = '/media/maximos/9C33-6BBD/data/melos_singers/features/multitask_targets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unnamed: 0', 'names', 'singer_id', 'Pitch', 'SpectralCentroid', 'SpectralSpread', 'SpectralSkewness', 'SpectralKurtosis', 'SpectralFlatness', 'SpectralCrest', 'SpectralSlope', 'SpectralDecrease', 'SpectralRollOff', 'SpectralVariation', 'SpectralFlux', 'HarmonicSpectralDeviation', 'Tristimulus_1', 'Tristimulus_2', 'Tristimulus_3', 'HarmonicOddToEvenRatio', 'Inharmonicity', 'HarmonicEnergy', 'NoiseEnergy', 'Noisiness', 'HarmonicToNoiseEnergy', 'PartialsToNoiseEnergy', 'F1_Hz', 'F2_Hz', 'F3_HZ', 'F4_Hz', 'Rate', 'Depth', 'Regularity']\n",
      "['singer_id', 'Pitch', 'SpectralCentroid', 'SpectralSpread', 'SpectralSkewness', 'SpectralKurtosis', 'SpectralFlatness', 'SpectralCrest', 'SpectralSlope', 'SpectralDecrease', 'SpectralRollOff', 'SpectralVariation', 'SpectralFlux', 'HarmonicSpectralDeviation', 'Tristimulus_1', 'Tristimulus_2', 'Tristimulus_3', 'HarmonicOddToEvenRatio', 'Inharmonicity', 'HarmonicEnergy', 'NoiseEnergy', 'Noisiness', 'HarmonicToNoiseEnergy', 'PartialsToNoiseEnergy', 'F1_Hz', 'F2_Hz', 'F3_HZ', 'F4_Hz', 'Rate', 'Depth', 'Regularity']\n"
     ]
    }
   ],
   "source": [
    "feats = pd.read_csv(csv_path, delimiter=',')\n",
    "features_list = list(feats.columns)\n",
    "print(features_list)\n",
    "del(features_list[:2])\n",
    "print(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pitch': 1, 'SpectralCentroid': 1, 'SpectralSpread': 1, 'SpectralSkewness': 1, 'SpectralKurtosis': 1, 'SpectralFlatness': 1, 'SpectralCrest': 1, 'SpectralSlope': 1, 'SpectralDecrease': 1, 'SpectralRollOff': 1, 'SpectralVariation': 1, 'SpectralFlux': 1, 'HarmonicSpectralDeviation': 1, 'Tristimulus_1': 1, 'Tristimulus_2': 1, 'Tristimulus_3': 1, 'HarmonicOddToEvenRatio': 1, 'Inharmonicity': 1, 'HarmonicEnergy': 1, 'NoiseEnergy': 1, 'Noisiness': 1, 'HarmonicToNoiseEnergy': 1, 'PartialsToNoiseEnergy': 1, 'F1_Hz': 1, 'F2_Hz': 1, 'F3_HZ': 1, 'F4_Hz': 1, 'singer_id': 6}\n"
     ]
    }
   ],
   "source": [
    "task_labels_num_out = {}\n",
    "for i in range(1, len(features_list)-3, 1):\n",
    "    task_labels_num_out[features_list[i]] = 1\n",
    "# add singer identification\n",
    "task_labels_num_out['singer_id'] = feats['singer_id'].max()+1 # accounting for zero\n",
    "print(task_labels_num_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = HuBERTMultiHead(task_labels_num_out=task_labels_num_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SingerMultiTaskDataset(train_audio_folder, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': array([ 9.6231786e-05, -4.8065151e-04, -1.0562916e-03, ...,\n",
      "        2.1723036e-02,  3.0537494e-02,  3.0633982e-02], dtype=float32), 'labels': {'Unnamed: 0': 235, 'names': 'keti_grei_e_7', 'singer_id': 3, 'Pitch': 442.967567138073, 'SpectralCentroid': 1649.18342861135, 'SpectralSpread': 1091.55349106278, 'SpectralSkewness': 1.37180571109231, 'SpectralKurtosis': 5.05492277926304, 'SpectralFlatness': 1.19733652424461e-09, 'SpectralCrest': 0.246353359792086, 'SpectralSlope': 1.0414362293082e-06, 'SpectralDecrease': 0.0087732118944919, 'SpectralRollOff': 2131.34777604787, 'SpectralVariation': 0.861851957216352, 'SpectralFlux': 0.001313200733224, 'HarmonicSpectralDeviation': 0.012296689893735, 'Tristimulus_1': 0.250974023096942, 'Tristimulus_2': 0.590761277109722, 'Tristimulus_3': 0.140094494653077, 'HarmonicOddToEvenRatio': 0.381924585198844, 'Inharmonicity': 0.0848189851447228, 'HarmonicEnergy': 0.0184961146711919, 'NoiseEnergy': 0.029466693442144, 'Noisiness': 0.498319194751083, 'HarmonicToNoiseEnergy': 0.941382100869722, 'PartialsToNoiseEnergy': 1.00675225464119, 'F1_Hz': 776.231683, 'F2_Hz': 1771.822117, 'F3_HZ': 3258.535735, 'F4_Hz': 3876.085193, 'Rate': 0.97878196, 'Depth': 0.109985736, 'Regularity': 0.470908039}}\n"
     ]
    }
   ],
   "source": [
    "print(training_data[235])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(training_data, batch_size=8, shuffle=True, collate_fn=model.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': <multitask_dataset.SingerMultiTaskDataset object at 0x770f70117a70>, 'num_workers': 0, 'prefetch_factor': None, 'pin_memory': False, 'pin_memory_device': '', 'timeout': 0, 'worker_init_fn': None, '_DataLoader__multiprocessing_context': None, '_dataset_kind': 0, 'batch_size': 8, 'drop_last': False, 'sampler': <torch.utils.data.sampler.RandomSampler object at 0x770efbe2e630>, 'batch_sampler': <torch.utils.data.sampler.BatchSampler object at 0x770efbe2d0a0>, 'generator': None, 'collate_fn': <bound method HuBERTMultiHead.collate_fn of HuBERTMultiHead(\n",
      "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): ParametrizedConv1d(\n",
      "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "        (parametrizations): ModuleDict(\n",
      "          (weight): ParametrizationList(\n",
      "            (0): _WeightNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hubert): Wav2Vec2Model(\n",
      "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Wav2Vec2GroupNormConvLayer(\n",
      "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (feature_projection): Wav2Vec2FeatureProjection(\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Wav2Vec2Encoder(\n",
      "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "        (conv): ParametrizedConv1d(\n",
      "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (padding): Wav2Vec2SamePadLayer()\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")>, 'persistent_workers': False, '_DataLoader__initialized': True, '_IterableDataset_len_called': None, '_iterator': None}\n"
     ]
    }
   ],
   "source": [
    "print(dataloader.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "33\n",
      "{'Unnamed: 0': [210, 56, 108, 276, 87, 146, 203, 79], 'names': ['keti_grei_a_1', 'bithikotsis_i_8', 'kazantzidis_i_14', 'ninou_e_4', 'kazantzidis_a_5', 'kazantzidis_old_i_10', 'kazantzidis_w_3', 'kazantzidis_a_18'], 'singer_id': [3, 1, 2, 4, 2, 2, 2, 2], 'Pitch': [535.988137952919, 196.750559613665, 196.296494053867, 440.92541806362, 197.319618870527, 215.925616065187, 267.066879934111, 226.922721646777], 'SpectralCentroid': [1604.22246900928, 1419.84821259399, 1705.6862093644, 2315.1939196014, 1155.50786599725, 1279.92643832382, 1034.77067769143, 1378.59343963769], 'SpectralSpread': [891.23944864804, 1202.39892206693, 1222.06835521984, 980.670723392669, 660.360208233537, 1090.27664505363, 756.039230893439, 789.04951998153], 'SpectralSkewness': [1.30524323043544, 0.699908105151804, 0.263777843232345, -0.423891811380255, 1.63228118840777, 0.815500213748112, 2.20245924197386, 1.19002708161243], 'SpectralKurtosis': [4.184987924076, 2.39864388048342, 2.33527538222561, 2.49429540134538, 6.21921967166814, 2.99738958600815, 8.05303542055374, 4.29343944405677], 'SpectralFlatness': [1.26154156624983e-05, 9.01181329139351e-07, 1.44637087784792e-10, 0.0025180227641146, 5.60252093582566e-10, 1.10653014835008e-06, 7.29442143692697e-06, 7.344863950789981e-09], 'SpectralCrest': [0.226024043027052, 0.286504993551371, 0.197861151647451, 0.152598029901101, 0.279856669743022, 0.27987196403777, 0.378416576222986, 0.186633687979549], 'SpectralSlope': [7.2923940531602e-08, 1.26390227028914e-07, 1.71806693356478e-06, 5.49284241626275e-08, 2.39883631433996e-06, -5.00495132354474e-07, -8.95309309346055e-07, 1.60053723468722e-06], 'SpectralDecrease': [0.0287200487801676, 0.0236060093614451, 0.0057010728866695, 0.0395172269368065, 0.0132012362817011, 0.0451888716124345, 0.054820429738971, 0.0156787982390016], 'SpectralRollOff': [3531.93526090275, 4096.34117937285, 3513.09810353334, 3989.11006258307, 2004.31237441914, 3272.24208278302, 3126.72534323937, 3273.64444661962], 'SpectralVariation': [0.683682505233386, 0.677639214391859, 0.760637620158902, 0.71872637642703, 0.532059521559602, 0.49243154700806, 0.698290877857338, 0.546125094693906], 'SpectralFlux': [0.0023661730006811, 0.002004168634722, 0.0009638056030281, 0.0020091110744367, 0.001234887024415, 0.0044820450137554, 0.0038244322863485, 0.0010020875276141], 'HarmonicSpectralDeviation': [0.0074626297813747, 0.0057423988596024, 0.0049559847643581, 0.0036930891179951, 0.0057872121824742, 0.0065562414797044, 0.0076889890118868, 0.0076071470090746], 'Tristimulus_1': [0.32444181812772, 0.178907835850924, 0.295299130794015, 0.413894781428408, 0.0558481805463729, 0.298946822314005, 0.0976506440824585, 0.0456316776030261], 'Tristimulus_2': [0.629015266350567, 0.563858631718232, 0.303821691546152, 0.23922364204673, 0.495752553540406, 0.270170841125316, 0.75654285493784, 0.360413249001933], 'Tristimulus_3': [0.0464616702181413, 0.242378895221502, 0.275705102795834, 0.196093105825914, 0.344536153575945, 0.429416522523647, 0.0670616677561398, 0.585130826054274], 'HarmonicOddToEvenRatio': [2.416212260337, 0.272323284773011, 1.3687732511466, 4.01189727033077, 0.417915802555276, 1.52921883808322, 0.111300090202982, 1.63934175898661], 'Inharmonicity': [0.175099666351477, 0.11946129892047, 0.199299436848608, 0.304372520112299, 0.223243719483597, 0.103353703525949, 0.145510457090189, 0.150845190863274], 'HarmonicEnergy': [0.0096369305695584, 0.0189724926786946, 0.0219176194348916, 0.0046004418610833, 0.0023213428718675, 0.0353681758713297, 0.010179880920869, 0.0207766080101187], 'NoiseEnergy': [0.0350876171112516, 0.0195154824034198, 0.0319182586779836, 0.0316441101350941, 0.015113681016523, 0.0273510938282581, 0.016298177752841, 0.0173002635352763], 'Noisiness': [0.628398666518965, 0.447458147972842, 0.507964109946549, 0.720264186717421, 0.486635686525753, 0.431308654736199, 0.501188563393449, 0.449870380275408], 'HarmonicToNoiseEnergy': [0.296710715035705, 1.13275653100568, 0.648588820337014, 0.156682863772086, 0.320383952471516, 1.30287318250914, 0.621710017796536, 1.14924297387309], 'PartialsToNoiseEnergy': [0.591346470449297, 1.23484588342035, 0.968645042246421, 0.388379511824101, 1.05492533262268, 1.31852523988872, 0.995306029079689, 1.22286252245389], 'F1_Hz': [997.772778, 463.772253, 334.420192, 763.442082, 789.436372, 370.121298, 603.347555, 870.984607], 'F2_Hz': [1635.120952, 2157.211678, 2119.074987, 2255.584252, 1439.816437, 1934.059996, 1180.226982, 1549.486829], 'F3_HZ': [1748.909816, 2583.811432, 2442.946446, 2264.599536, 2440.292228, 2340.227153, 2554.925284, 2685.076668], 'F4_Hz': [3242.144595, 3697.487087, 3367.78672, 3230.396079, 3610.099368, 3056.525748, 3622.61078, 3645.467436], 'Rate': [3.054355053, 1.848343616, 2.208533654, 5.066636029, 0.997677365, 0.861328125, 1.72265625, 3.408132869], 'Depth': [0.126504316, 0.020038547, 0.062350976, 0.082863123, 2.916665217, 0.03095827, 0.154980529, 0.249474341], 'Regularity': [0.378211725, 0.041061582, 0.000450097, 0.300905587, 0.187577527, 0.047193955, 0.361190079, 0.110636079]}\n"
     ]
    }
   ],
   "source": [
    "print(len(b[0]['input_values']))\n",
    "print(len(b[0]['attention_mask']))\n",
    "print(len(b[1]))\n",
    "print(b[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43maudio_normalized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_values\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/torchaudio/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda/envs/torchaudio/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/media/maximos/9C33-6BBD/repos/singer_feature_multi_regression/models.py:80\u001b[0m, in \u001b[0;36mHuBERTMultiHead.forward\u001b[0;34m(self, audio_normalized, attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels[task_name] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels[task_name] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtask_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mlong \u001b[38;5;129;01mor\u001b[39;00m labels[task_name]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mint\n\u001b[1;32m     81\u001b[0m ):\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle_label_classification\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "y = model(\n",
    "    audio_normalized=b[0]['input_values'],\n",
    "    attention_mask=b[0]['attention_mask'],\n",
    "    labels=b[1],\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
