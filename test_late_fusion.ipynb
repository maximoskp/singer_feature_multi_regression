{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multitask_dataset import SingerMultiTaskDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from models import HuBERTLateFeatureFusion\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from torchview import draw_graph\n",
    "import torchvision\n",
    "# from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "\n",
    "# import torch\n",
    "# torch.autograd.detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_audio_folder = '/media/maindisk/maximos/data/melos_singers/Rebetika_vowels/train/'\n",
    "# csv_path = '/media/maindisk/maximos/data/melos_singers/features/multitask_targets.csv'\n",
    "train_audio_folder = '/media/maximos/9C33-6BBD/data/melos_singers/Rebetika_vowels/train/'\n",
    "csv_path = '/media/maximos/9C33-6BBD/data/melos_singers/features/multitask_targets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['singer_id', 'Pitch', 'SpectralCentroid', 'SpectralSpread', 'SpectralSkewness', 'SpectralKurtosis', 'SpectralFlatness', 'SpectralCrest', 'SpectralSlope', 'SpectralDecrease', 'SpectralRollOff', 'SpectralVariation', 'SpectralFlux', 'HarmonicSpectralDeviation', 'Tristimulus_1', 'Tristimulus_2', 'Tristimulus_3', 'HarmonicOddToEvenRatio', 'Inharmonicity', 'HarmonicEnergy', 'NoiseEnergy', 'Noisiness', 'HarmonicToNoiseEnergy', 'PartialsToNoiseEnergy', 'F1_Hz', 'F2_Hz', 'F3_HZ', 'F4_Hz', 'Rate', 'Depth', 'Regularity']\n"
     ]
    }
   ],
   "source": [
    "feats = pd.read_csv(csv_path, delimiter=',')\n",
    "features_list = list(feats.columns)\n",
    "del(features_list[:2])\n",
    "print(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pitch': 1, 'SpectralCentroid': 1, 'SpectralSpread': 1, 'SpectralSkewness': 1, 'SpectralKurtosis': 1, 'SpectralFlatness': 1, 'SpectralCrest': 1, 'SpectralSlope': 1, 'SpectralDecrease': 1, 'SpectralRollOff': 1, 'SpectralVariation': 1, 'SpectralFlux': 1, 'HarmonicSpectralDeviation': 1, 'Tristimulus_1': 1, 'Tristimulus_2': 1, 'Tristimulus_3': 1, 'HarmonicOddToEvenRatio': 1, 'Inharmonicity': 1, 'HarmonicEnergy': 1, 'NoiseEnergy': 1, 'Noisiness': 1, 'HarmonicToNoiseEnergy': 1, 'PartialsToNoiseEnergy': 1, 'F1_Hz': 1, 'F2_Hz': 1, 'F3_HZ': 1, 'F4_Hz': 1, 'singer_id': 6}\n"
     ]
    }
   ],
   "source": [
    "task_labels_num_out = {}\n",
    "for i in range(1, len(features_list)-3, 1):\n",
    "    task_labels_num_out[features_list[i]] = 1\n",
    "# add singer identification\n",
    "task_labels_num_out['singer_id'] = feats['singer_id'].max()+1 # accounting for zero\n",
    "print(task_labels_num_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = HuBERTLateFeatureFusion(task_labels_num_out=task_labels_num_out, gpu_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SingerMultiTaskDataset(train_audio_folder, csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(training_data, batch_size=4, shuffle=True, collate_fn=model.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep hubert frozen\n",
    "for p in model.hubert.parameters():\n",
    "    p.requires_grad = False\n",
    "# train projectors and classifiers\n",
    "for k in model.projectors.keys():\n",
    "    model.projectors[k].requires_grad = True\n",
    "    model.classifiers[k].requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam( model.parameters(), lr=0.001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(\n",
    "    audio_normalized=b[0]['input_values'],\n",
    "    attention_mask=b[0]['attention_mask'],\n",
    "    labels=b[1],\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regressors': tensor(1.1165, device='cuda:0', grad_fn=<AddBackward0>), 'classifier': tensor(1.7618, device='cuda:0', grad_fn=<NllLossBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "print(y.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.0141e-12,  7.8632e-10,  1.3504e-10,  ...,  1.5434e-08,\n",
      "          5.8117e-10, -3.8207e-08],\n",
      "        [ 2.9763e-07,  9.2447e-07,  1.5113e-07,  ...,  1.7522e-07,\n",
      "          3.0023e-07, -5.4433e-05],\n",
      "        [-5.0201e-10, -1.9900e-08, -7.6184e-09,  ..., -4.2044e-09,\n",
      "          5.1895e-07,  1.5639e-06],\n",
      "        ...,\n",
      "        [ 9.5809e-07,  2.7300e-06,  4.7807e-07,  ..., -2.6590e-06,\n",
      "          8.2890e-07, -1.6958e-04],\n",
      "        [ 1.2446e-06,  3.9087e-06,  7.8115e-07,  ..., -4.1634e-06,\n",
      "         -1.0613e-05, -2.5155e-04],\n",
      "        [-5.7263e-09, -1.4922e-08, -2.7208e-09,  ...,  3.8041e-08,\n",
      "         -4.0654e-09,  9.6481e-07]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.intermediates['Pitch'].weight.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()\n",
    "# y.loss['regressors'].backward(retain_graph=True)# retain_graph=True\n",
    "# y.loss['classifier'].backward()# retain_graph=True\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "(y.loss['regressors'] + y.loss['classifier']).backward()\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
