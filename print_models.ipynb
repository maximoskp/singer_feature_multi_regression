{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maximos/miniconda3/envs/torchaudio/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from models import HuBERTClassifierBaseline, HuBERTNoFusion, HuBERTEarlyFeatureFusion, HuBERTLateFeatureFusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from multitask_dataset import SingerMultiTaskDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_folder = '/media/maindisk/maximos/data/melos_singers/Rebetika_vowels/train/'\n",
    "test_audio_folder = '/media/maindisk/maximos/data/melos_singers/Rebetika_vowels/test/'\n",
    "csv_path = '/media/maindisk/maximos/data/melos_singers/features/multitask_targets.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv\n",
    "feats = pd.read_csv(csv_path, delimiter=',')\n",
    "# keep feature list which will become the tasks\n",
    "features_list = list(feats.columns)\n",
    "# delete unnecessary columns\n",
    "del(features_list[:2])\n",
    "\n",
    "# keep number of outputs per task\n",
    "task_labels_num_out = {}\n",
    "for i in range(1, len(features_list)-3, 1):\n",
    "    task_labels_num_out[features_list[i]] = 1\n",
    "# add singer identification\n",
    "task_labels_num_out['singer_id'] = feats['singer_id'].max()+1 # accounting for zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a model of type hubert to instantiate a model of type wav2vec2. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huBERTClassifierBaseline = HuBERTClassifierBaseline(task_labels_num_out=task_labels_num_out, gpu_index=0)\n",
    "huBERTNoFusion = HuBERTNoFusion(task_labels_num_out=task_labels_num_out, gpu_index=0)\n",
    "huBERTEarlyFeatureFusion = HuBERTEarlyFeatureFusion(task_labels_num_out=task_labels_num_out, gpu_index=0)\n",
    "huBERTLateFeatureFusion = HuBERTLateFeatureFusion(task_labels_num_out=task_labels_num_out, gpu_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = SingerMultiTaskDataset(train_audio_folder, csv_path)\n",
    "dataloader = DataLoader(training_data, batch_size=4, shuffle=True, collate_fn=huBERTClassifierBaseline.collate_fn)\n",
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = huBERTClassifierBaseline(\n",
    "    audio_normalized=b[0]['input_values'],\n",
    "    attention_mask=b[0]['attention_mask'],\n",
    "    labels=b[1],\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False,\n",
    "    return_dict=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# print(huBERTClassifierBaseline)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(huBERTClassifierBaseline.named_parameters())\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# make_dot( y.logits['singer_id'][0], params=dict(huBERTClassifierBaseline.named_parameters()) )\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_normalized\u001b[39m\u001b[38;5;124m'\u001b[39m:b[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m:b[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     11\u001b[0m }\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuBERTClassifierBaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuBERTClassifierBaseline.onnx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mins\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mouts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/onnx/utils.py:516\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;129m@_beartype\u001b[39m\u001b[38;5;241m.\u001b[39mbeartype\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\n\u001b[1;32m    191\u001b[0m     model: Union[torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptModule, torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mScriptFunction],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m     autograd_inlining: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    209\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Exports a model into ONNX format.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03m    If ``model`` is not a :class:`torch.jit.ScriptModule` nor a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m            All errors are subclasses of :class:`errors.OnnxExporterError`.\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/onnx/utils.py:1613\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1610\u001b[0m     dynamic_axes \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1611\u001b[0m _validate_dynamic_axes(dynamic_axes, model, input_names, output_names)\n\u001b[0;32m-> 1613\u001b[0m graph, params_dict, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_model_to_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1617\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1618\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1619\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_do_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfixed_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfixed_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;66;03m# TODO: Don't allocate a in-memory string for the protobuf\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m defer_weight_export \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1628\u001b[0m     export_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _exporter_states\u001b[38;5;241m.\u001b[39mExportTypes\u001b[38;5;241m.\u001b[39mPROTOBUF_FILE\n\u001b[1;32m   1629\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/onnx/utils.py:1135\u001b[0m, in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[1;32m   1134\u001b[0m model \u001b[38;5;241m=\u001b[39m _pre_trace_quant_model(model, args)\n\u001b[0;32m-> 1135\u001b[0m graph, params, torch_out, module \u001b[38;5;241m=\u001b[39m \u001b[43m_create_jit_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1136\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m _get_named_param_dict(graph, params)\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/onnx/utils.py:1011\u001b[0m, in \u001b[0;36m_create_jit_graph\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m   1006\u001b[0m     graph \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39m_propagate_and_assign_input_shapes(\n\u001b[1;32m   1007\u001b[0m         graph, flattened_args, param_count_list, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m     )\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m graph, params, torch_out, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1011\u001b[0m graph, torch_out \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_and_get_graph_from_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m _C\u001b[38;5;241m.\u001b[39m_jit_pass_onnx_lint(graph)\n\u001b[1;32m   1013\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_unique_state_dict(model)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/onnx/utils.py:915\u001b[0m, in \u001b[0;36m_trace_and_get_graph_from_model\u001b[0;34m(model, args)\u001b[0m\n\u001b[1;32m    913\u001b[0m prev_autocast_cache_enabled \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_autocast_cache_enabled()\n\u001b[1;32m    914\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 915\u001b[0m trace_graph, torch_out, inputs_states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_trace_graph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_autocast_cache_enabled(prev_autocast_cache_enabled)\n\u001b[1;32m    924\u001b[0m warn_on_static_input_change(inputs_states)\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/jit/_trace.py:1296\u001b[0m, in \u001b[0;36m_get_trace_graph\u001b[0;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m   1295\u001b[0m     args \u001b[38;5;241m=\u001b[39m (args,)\n\u001b[0;32m-> 1296\u001b[0m outs \u001b[38;5;241m=\u001b[39m \u001b[43mONNXTracedModule\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_return_inputs_states\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/torchaudio/lib/python3.12/site-packages/torch/jit/_trace.py:105\u001b[0m, in \u001b[0;36mONNXTracedModule.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 105\u001b[0m     in_vars, in_desc \u001b[38;5;241m=\u001b[39m \u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# NOTE: use full state, because we need it for BatchNorm export\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# This differs from the compiler path, which doesn't support it at the moment.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     module_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(_unique_state_dict(\u001b[38;5;28mself\u001b[39m, keep_vars\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mvalues())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# print(huBERTClassifierBaseline)\n",
    "# print(huBERTClassifierBaseline.named_parameters())\n",
    "# make_dot( y.logits['singer_id'][0], params=dict(huBERTClassifierBaseline.named_parameters()) )\n",
    "X = {\n",
    "    'audio_normalized':b[0]['input_values'],\n",
    "    'attention_mask':b[0]['attention_mask'],\n",
    "    'labels':b[1],\n",
    "    'output_attentions':False,\n",
    "    'output_hidden_states':False,\n",
    "    'return_dict':True\n",
    "}\n",
    "torch.onnx.export(huBERTClassifierBaseline, X, \"huBERTClassifierBaseline.onnx\", input_names='ins', output_names='outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuBERTNoFusion(\n",
      "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): ParametrizedConv1d(\n",
      "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "        (parametrizations): ModuleDict(\n",
      "          (weight): ParametrizationList(\n",
      "            (0): _WeightNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hubert): Wav2Vec2Model(\n",
      "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Wav2Vec2GroupNormConvLayer(\n",
      "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (feature_projection): Wav2Vec2FeatureProjection(\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Wav2Vec2Encoder(\n",
      "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "        (conv): ParametrizedConv1d(\n",
      "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (padding): Wav2Vec2SamePadLayer()\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (intermediates): ModuleDict(\n",
      "    (Pitch): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (Noisiness): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (F1_Hz): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (F2_Hz): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (F3_HZ): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (F4_Hz): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (singer_id): Linear(in_features=768, out_features=512, bias=True)\n",
      "  )\n",
      "  (projectors): ModuleDict(\n",
      "    (Pitch): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Noisiness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F1_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F2_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F3_HZ): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F4_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (singer_id): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (classifiers): ModuleDict(\n",
      "    (Pitch): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Noisiness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F1_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F2_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F3_HZ): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F4_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (singer_id): Linear(in_features=256, out_features=7, bias=True)\n",
      "  )\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(huBERTNoFusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuBERTEarlyFeatureFusion(\n",
      "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): ParametrizedConv1d(\n",
      "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "        (parametrizations): ModuleDict(\n",
      "          (weight): ParametrizationList(\n",
      "            (0): _WeightNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hubert): Wav2Vec2Model(\n",
      "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Wav2Vec2GroupNormConvLayer(\n",
      "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (feature_projection): Wav2Vec2FeatureProjection(\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Wav2Vec2Encoder(\n",
      "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "        (conv): ParametrizedConv1d(\n",
      "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (padding): Wav2Vec2SamePadLayer()\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (common_base_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "  (common_base_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (common_projector): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (intermediates): ModuleDict(\n",
      "    (Pitch): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Noisiness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F1_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F2_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F3_HZ): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F4_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (singer_id): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (projectors): ModuleDict(\n",
      "    (Pitch): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Noisiness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F1_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F2_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F3_HZ): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F4_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (singer_id): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (classifiers): ModuleDict(\n",
      "    (Pitch): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Noisiness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F1_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F2_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F3_HZ): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F4_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (singer_id): Linear(in_features=256, out_features=7, bias=True)\n",
      "  )\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(huBERTEarlyFeatureFusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HuBERTLateFeatureFusion(\n",
      "  (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): ParametrizedConv1d(\n",
      "        768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "        (parametrizations): ModuleDict(\n",
      "          (weight): ParametrizationList(\n",
      "            (0): _WeightNorm()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (hubert): Wav2Vec2Model(\n",
      "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
      "      (conv_layers): ModuleList(\n",
      "        (0): Wav2Vec2GroupNormConvLayer(\n",
      "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "        )\n",
      "        (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "        (5-6): 2 x Wav2Vec2NoLayerNormConvLayer(\n",
      "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "          (activation): GELUActivation()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (feature_projection): Wav2Vec2FeatureProjection(\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): Wav2Vec2Encoder(\n",
      "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "        (conv): ParametrizedConv1d(\n",
      "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
      "          (parametrizations): ModuleDict(\n",
      "            (weight): ParametrizationList(\n",
      "              (0): _WeightNorm()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (padding): Wav2Vec2SamePadLayer()\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "          (attention): Wav2Vec2Attention(\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (feed_forward): Wav2Vec2FeedForward(\n",
      "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (common_base_1): Linear(in_features=768, out_features=2048, bias=True)\n",
      "  (common_base_2): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (common_projector): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (intermediates): ModuleDict(\n",
      "    (Pitch): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (Noisiness): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F1_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F2_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F3_HZ): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (F4_Hz): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (singer_id): Linear(in_features=6912, out_features=512, bias=True)\n",
      "  )\n",
      "  (projectors): ModuleDict(\n",
      "    (Pitch): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (Noisiness): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F1_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F2_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F3_HZ): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (F4_Hz): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (singer_id): Linear(in_features=512, out_features=256, bias=True)\n",
      "  )\n",
      "  (classifiers): ModuleDict(\n",
      "    (Pitch): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCentroid): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSpread): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSkewness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralKurtosis): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlatness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralCrest): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralSlope): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralDecrease): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralRollOff): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralVariation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (SpectralFlux): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicSpectralDeviation): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_1): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_2): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Tristimulus_3): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicOddToEvenRatio): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Inharmonicity): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (NoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (Noisiness): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (HarmonicToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (PartialsToNoiseEnergy): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F1_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F2_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F3_HZ): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (F4_Hz): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (singer_id): Linear(in_features=256, out_features=7, bias=True)\n",
      "  )\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (softmax): Softmax(dim=1)\n",
      "  (sigmoid): Sigmoid()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(huBERTLateFeatureFusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchaudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
